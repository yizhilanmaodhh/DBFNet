{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Fl0CNUVbhSr6"},"outputs":[],"source":["import numpy as np\n","from PIL import Image\n","import skimage\n","from skimage import io, measure\n","import random\n","import scipy.io as sio\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from preclassify import del2, srad, dicomp, FCM, hcluster\n","import torch\n","import torchvision\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import cv2\n","from collections import  Counter\n","\n","im1_path  = 'im1.bmp'\n","im2_path  = 'im2.bmp'\n","imgt_path = 'im3.bmp'\n","\n","patch_size = 9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Oe-Fm8khc7x"},"outputs":[],"source":["def image_normalize(data):  # 对图像进行标准化\n","  import math\n","  _mean = np.mean(data)\n","  _std = np.std(data)\n","  npixel = np.size(data) * 1.0\n","  min_stddev = 1.0 / math.sqrt(npixel)\n","  return (data - _mean) / max(_std, min_stddev)\n","\n","def image_padding(data,r):\n","  if len(data.shape)==3:\n","    data_new=np.lib.pad(data,((r,r),(r,r),(0,0)),'constant',constant_values=0)\n","    return data_new\n","  if len(data.shape)==2:\n","    data_new=np.lib.pad(data,r,'constant',constant_values=0)\n","    return data_new\n","\n","def arr(length):\n","  arr=np.arange(length-1)\n","  #print(arr)\n","  random.shuffle(arr)\n","  #print(arr)\n","  return arr\n","\n","\n","def createTrainingCubes(X, y, patch_size):   # 创建训练数据集\n","  # 给 X 做 padding\n","  margin = int((patch_size - 1) / 2)\n","  zeroPaddedX = image_padding(X, margin)\n","  ele_num1 = np.sum(y==1)\n","  ele_num2 = np.sum(y==2)\n","  patchesData_1 = np.zeros((ele_num1, patch_size, patch_size, X.shape[2]))\n","  patchesLabels_1 = np.zeros(ele_num1)\n","\n","  patchesData_2 = np.zeros((ele_num2, patch_size, patch_size, X.shape[2]))\n","  patchesLabels_2 = np.zeros(ele_num2)\n","\n","  patchIndex_1 = 0\n","  patchIndex_2 = 0\n","  for r in range(margin, zeroPaddedX.shape[0] - margin):\n","    for c in range(margin, zeroPaddedX.shape[1] - margin):\n","      # remove uncertainty pixels\n","      if y[r-margin, c-margin] == 1 :\n","        patch_1 = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n","        patchesData_1[patchIndex_1, :, :, :] = patch_1\n","        patchesLabels_1[patchIndex_1] = y[r-margin, c-margin]\n","        patchIndex_1 = patchIndex_1 + 1\n","      elif y[r-margin, c-margin] == 2 :\n","        patch_2 = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n","        patchesData_2[patchIndex_2, :, :, :] = patch_2\n","        patchesLabels_2[patchIndex_2] = y[r-margin, c-margin]\n","        patchIndex_2 = patchIndex_2 + 1\n","  patchesLabels_1 = patchesLabels_1-1\n","  patchesLabels_2 = patchesLabels_2-1\n","\n","  arr_1=arr(len(patchesData_1))\n","  arr_2=arr(len(patchesData_2))\n","\n","  train_len=10000\n","  pdata=np.zeros((train_len, patch_size, patch_size, X.shape[2]))\n","  plabels = np.zeros(train_len)\n","\n","  for i in range(7000):\n","    pdata[i,:,:,:]=patchesData_1[arr_1[i],:,:,:]\n","    plabels[i]=patchesLabels_1[arr_1[i]]\n","  for j in range(7000,train_len):\n","    pdata[j,:,:,:]=patchesData_2[arr_2[j-7000],:,:,:]\n","    plabels[j]=patchesLabels_2[arr_2[j-7000]]\n","\n","  return pdata, plabels\n","\n","def createTestingCubes(X,patch_size):   # 创建测试数据集\n","  # 给 X 做 padding\n","  margin = int((patch_size - 1) / 2)\n","  zeroPaddedX = image_padding(X, margin)\n","  patchesData = np.zeros((X.shape[0]*X.shape[1], patch_size, patch_size, X.shape[2]))\n","  patchIndex = 0\n","  for r in range(margin, zeroPaddedX.shape[0] - margin):\n","    for c in range(margin, zeroPaddedX.shape[1] - margin):\n","      patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n","      patchesData[patchIndex, :, :, :] = patch\n","      patchIndex = patchIndex + 1\n","  return patchesData\n","\n","\n","#  Inputs:  gtImg  = ground truth image\n","#           tstImg = change map\n","#  Outputs: FA  = False alarms\n","#           MA  = Missed alarms\n","#           OE  = Overall error\n","#           PCC = Overall accuracy\n","def evaluate(gtImg, tstImg):\n","  if gtImg.ndim != 2:\n","    raise ValueError(\"gtImg should be a 2D array\")\n","  if tstImg.ndim != 2:\n","    raise ValueError(\"tstImg should be a 2D array\")\n","  gtImg[np.where(gtImg>128)] = 255\n","  gtImg[np.where(gtImg<128)] = 0\n","  tstImg[np.where(tstImg>128)] = 255\n","  tstImg[np.where(tstImg<128)] = 0\n","  [ylen, xlen] = gtImg.shape\n","  FA = 0\n","  MA = 0\n","  label_0 = np.sum(gtImg==0)\n","  label_1 = np.sum(gtImg==255)\n","  print(label_0)\n","  print(label_1)\n","\n","  for j in range(0,ylen):\n","    for i in range(0,xlen):\n","      if gtImg[j,i]==0 and tstImg[j,i]!=0 :\n","        FA = FA+1\n","      if gtImg[j,i]!=0 and tstImg[j,i]==0 :\n","        MA = MA+1\n","\n","  OE = FA+MA\n","  PCC = 1-OE/(ylen*xlen)\n","  PRE = (np.float64(label_1) + FA - MA) * label_1 + (np.float64(label_0) + MA - FA) * label_0\n","  PRE = PRE / (np.float64(ylen * xlen) * (ylen * xlen))\n","  KC=(PCC-PRE)/(1-PRE)\n","  print(' Change detection results ==>')\n","  print(' ... ... FP:  ', FA)\n","  print(' ... ... FN:  ', MA)\n","  print(' ... ... OE:  ', OE)\n","  print(' ... ... PCC: ', format(PCC*100, '.2f'))\n","  print(' ... ... KC: ', format(KC*100, '.2f'))\n","\n","def postprocess1(res):\n","  res_new = res\n","  res = measure.label(res, connectivity=2)\n","  #print(res)\n","  num = res.max()\n","  #print(num)\n","  for i in range(1, num+1):\n","    idy, idx = np.where(res==i)\n","    if len(idy) <= 20:\n","      res_new[idy, idx] = 0\n","  return res_new\n","\n","def postprocess(res):\n","  res_new = res\n","  res = measure.label(res, connectivity=2)\n","  #print(res)\n","  num = res.max()\n","  #print(num)\n","  for i in range(1, num+1):\n","    idy, idx = np.where(res==i)\n","    if len(idy) <= 20:\n","      res_new[idy, idx] = 0.5\n","  return res_new"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"V6HUsx3WhfpH"},"outputs":[],"source":["# read image, and then tranform to float32\n","from skimage.color import rgb2gray\n","import numpy as np\n","\n","im1 = io.imread(im1_path).astype(np.float32)\n","im2 = io.imread(im2_path).astype(np.float32)\n","\n","print(im1.shape)\n","print(im2.shape)\n","print(type(im1))\n","\n","\n","im_gt = io.imread(imgt_path).astype(np.float32)\n","\n","if im1.ndim == 3 and im1.shape[2] == 3:\n","    im1 = rgb2gray(im1)\n","if im2.ndim == 3 and im2.shape[2] == 3:\n","    im2 = rgb2gray(im2)\n","if im_gt.ndim == 3:\n","    im_gt = rgb2gray(im_gt).astype(np.uint8)\n","\n","im_di = dicomp(im1, im2)\n","ylen, xlen = im_di.shape\n","pix_vec = im_di.reshape([ylen*xlen, 1])\n","\n","preclassify_lab = hcluster(pix_vec, im_di)\n","print('... ... hiearchical clustering finished !!!')\n","\n","\n","mdata = np.zeros([im1.shape[0], im1.shape[1], 3], dtype=np.float32)\n","mdata[:,:,0] = im1\n","mdata[:,:,1] = im2\n","mdata[:,:,2] = im_di\n","mlabel = preclassify_lab\n","\n","x_train, y_train = createTrainingCubes(mdata, mlabel, patch_size)\n","x_train = x_train.transpose(0, 3, 1, 2)\n","print('... x train shape: ', x_train.shape)\n","print('... y train shape: ', y_train.shape)\n","\n","\n","x_test = createTestingCubes(mdata, patch_size)\n","x_test = x_test.transpose(0, 3, 1, 2)\n","print('... x test shape: ', x_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fq-QjHIihmu2"},"outputs":[],"source":["\"\"\" 训练数据集\"\"\"\n","class TrainDS(torch.utils.data.Dataset):\n","  def __init__(self):\n","    self.len = x_train.shape[0]\n","    self.x_data = torch.FloatTensor(x_train)\n","    self.y_data = torch.LongTensor(y_train)\n","  def __getitem__(self, index):\n","    return self.x_data[index], self.y_data[index]\n","  def __len__(self):\n","    return self.len\n","\n","trainset = TrainDS()\n","train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=128, shuffle=True, num_workers=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"K2YRz6Lvg9YP"},"outputs":[],"source":["from __future__ import print_function\n","\n","import glob\n","from itertools import chain\n","import os\n","import random\n","import zipfile\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import datasets, transforms\n","from tqdm.notebook import tqdm\n","\n","epochs = 10\n","lr = 1e-3\n","gamma = 0.7\n","seed = 42\n","def seed_everything(seed):\n","  random.seed(seed)\n","  os.environ['PYTHONHASHSEED'] = str(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"txyPj1ftEzHl"},"outputs":[],"source":["import torch\n","from torch import nn\n","from einops import rearrange, repeat\n","from einops.layers.torch import Rearrange\n","def pair(t):\n","  return t if isinstance(t, tuple) else (t, t)\n","\n","class Attention(nn.Module):\n","  def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n","    super().__init__()\n","    inner_dim = dim_head *  heads\n","    project_out = not (heads == 1 and dim_head == dim)\n","    self.heads = heads\n","    self.scale = dim_head ** -0.5\n","    self.attend = nn.Softmax(dim = -1)\n","    self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n","\n","    self.to_out = nn.Sequential(\n","        nn.Linear(inner_dim, dim),\n","        nn.Dropout(dropout)\n","    ) if project_out else nn.Identity()\n","  def forward(self, x):\n","    qkv = self.to_qkv(x).chunk(3, dim = -1)\n","    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n","    dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n","    attn = self.attend(dots)\n","    out = torch.matmul(attn, v)\n","    out = rearrange(out, 'b h n d -> b n (h d)')\n","    return self.to_out(out)\n","\n","class ViT(nn.Module):\n","  def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 1, dim_head = 64, dropout = 0., emb_dropout = 0.):\n","    super().__init__()\n","    image_height, image_width = pair(image_size)\n","    patch_height, patch_width = pair(patch_size)\n","    num_patches = (image_height // patch_height) * (image_width // patch_width)\n","    patch_dim = channels * patch_height * patch_width\n","    assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n","\n","    self.to_patch_embedding = nn.Sequential(\n","        Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n","        nn.Linear(patch_dim, patch_dim),\n","    )\n","    self.transformer = Attention(patch_dim, heads=heads, dim_head=dim_head, dropout=dropout)\n","    '''\n","    self.reshape = nn.Sequential(\n","        Rearrange('b (h w) c -> b c h w', h = image_height, w = image_width, c = channels),\n","    )\n","    '''\n","  def forward(self, img):\n","    x = self.to_patch_embedding(img)\n","    x = self.transformer(x)\n","    x = x.unsqueeze(1)\n","    return x\n","vit = ViT(\n","  image_size = 9,\n","  patch_size = 3,\n","  num_classes = 2,\n","  dim = 27,\n","  depth = 6,\n","  heads = 4,\n","  mlp_dim = 32,\n",").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3Qdm2pbGEzHl"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class BiAttention(nn.Module):\n","    def __init__(self, feature_dim=1):\n","        super(BiAttention, self).__init__()\n","        self.feature_dim = feature_dim\n","        self.proj1 = nn.Conv2d(1, self.feature_dim, kernel_size=3, padding=1)\n","        self.proj2 = nn.Conv2d(1, self.feature_dim, kernel_size=3, padding=1)\n","        self.bilinear_pool = nn.AdaptiveAvgPool2d((7, 7))\n","        self.proj_back = nn.Conv2d(self.feature_dim, 1, kernel_size=1)\n","\n","    def forward(self, img1, img2):\n","        print(\"input:\",img1.shape)\n","        img1_proj = self.proj1(img1)\n","        img2_proj = self.proj2(img2)\n","\n","        B, C, H, W = img1_proj.size()\n","        img1_flat = img1_proj.view(B*C, H, W)\n","        img2_flat = img2_proj.view(B*C, H, W)\n","        img2_flat_T = img2_flat.transpose(1, 2)\n","\n","        bilinear_features = torch.bmm(img1_flat, img2_flat_T)\n","        print(\"after bmm:\",bilinear_features.shape)\n","        bilinear_features = bilinear_features.view(B, 1, 9, 9)\n","        print(\"before:\",bilinear_features)\n","        bilinear_features = self.bilinear_pool(bilinear_features)\n","        print(\"after:\",bilinear_features)\n","        print(\"after pooling:\",bilinear_features.shape)\n","\n","        enhanced_feature = self.proj_back(bilinear_features)\n","\n","        return enhanced_feature"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"H6LZRS9QHWjP"},"outputs":[],"source":["class attention2d(nn.Module):\n","    def __init__(self, in_planes, ratios, K, temperature, init_weight=True):\n","        super(attention2d, self).__init__()\n","        assert temperature%3==1\n","        self.avgpool = nn.AdaptiveAvgPool2d(1)\n","        if in_planes!=3:\n","            hidden_planes = 2\n","        else:\n","            hidden_planes = 16\n","        self.fc1 = nn.Conv2d(in_planes, hidden_planes, 1, bias=False)\n","        self.fc2 = nn.Conv2d(hidden_planes, K, 1, bias=True)\n","        self.temperature = temperature\n","        if init_weight:\n","            self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            if isinstance(m ,nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def updata_temperature(self):\n","        if self.temperature!=1:\n","            self.temperature -=3\n","            print('Change temperature to:', str(self.temperature))\n","\n","    def forward(self, x):\n","        x = self.avgpool(x)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x).view(x.size(0), -1)\n","        return F.softmax(x/self.temperature, 1)\n","\n","\n","\n","class Dynamic_conv2d(nn.Module):\n","    def __init__(self, in_planes, out_planes, kernel_size, ratio=0.25, stride=1, padding=0, dilation=1, groups=1, bias=True, K=4,temperature=22, init_weight=True):\n","        super(Dynamic_conv2d, self).__init__()\n","        assert in_planes % groups==0\n","        self.in_planes = in_planes\n","        self.out_planes = out_planes\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        self.dilation = dilation\n","        self.groups = groups\n","        self.bias = bias\n","        self.K = K\n","        self.attention = attention2d(in_planes, ratio, K, temperature)\n","\n","        self.weight = nn.Parameter(torch.randn(K, out_planes, in_planes//groups, kernel_size, kernel_size), requires_grad=True)\n","        if bias:\n","            self.bias = nn.Parameter(torch.zeros(K, out_planes))\n","        else:\n","            self.bias = None\n","        if init_weight:\n","            self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        for i in range(self.K):\n","            nn.init.kaiming_uniform_(self.weight[i])\n","\n","    def update_temperature(self):\n","        self.attention.updata_temperature()\n","\n","    def forward(self, x):\n","        softmax_attention = self.attention(x)\n","\n","        batch_size, in_planes, height, width = x.size()\n","        x = x.view(1, -1, height, width)\n","        weight = self.weight.view(self.K, -1)\n","\n","        aggregate_weight = torch.mm(softmax_attention, weight).view(batch_size*self.out_planes, self.in_planes//self.groups, self.kernel_size, self.kernel_size)\n","        if self.bias is not None:\n","            aggregate_bias = torch.mm(softmax_attention, self.bias).view(-1)\n","            output = F.conv2d(x, weight=aggregate_weight, bias=aggregate_bias, stride=self.stride, padding=self.padding,\n","                              dilation=self.dilation, groups=self.groups*batch_size)\n","        else:\n","            output = F.conv2d(x, weight=aggregate_weight, bias=None, stride=self.stride, padding=self.padding,\n","                              dilation=self.dilation, groups=self.groups * batch_size)\n","\n","        output = output.view(batch_size, self.out_planes, output.size(-2), output.size(-1))\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"TkDTZvl2g1Rp"},"outputs":[],"source":["import math\n","def shift(y, n = 6):\n","  B, C, H, W = y.shape\n","  num = C // n\n","  out = torch.zeros_like(y)\n","  out[:, num * 0:num * 1, 1:, :] = y[:, num * 0:num * 1, :-1, :]  # shift down\n","  out[:, num * 1:num * 2, :-1, :] = y[:, num * 1:num * 2, 1:, :]  # shift up\n","  out[:, num * 2:num * 3, :, :-1] = y[:, num * 2:num * 3, :, 1:]  # shift left\n","  out[:, num * 3:num * 4, :, 1:] = y[:, num * 3:num * 4, :, :-1]  # shift right\n","  out[:, num * 4:, :, :] = y[:, num * 4:, :, :]  # no shift\n","  return out\n","class CSC(nn.Module):\n","  def __init__(self):\n","    super(CSC, self).__init__()\n","    self.conv1 = nn.Conv2d(1,12,1,1)\n","    self.shift = shift\n","    self.conv2 = nn.Conv2d(12,1,1,1)\n","    self.dconv1 = Dynamic_conv2d(in_planes=1, out_planes=12, kernel_size=1, ratio=0.25, stride=1, padding=0, dilation=1, groups=1, bias=True, K=4,temperature=37, init_weight=True)\n","    self.dconv2 = Dynamic_conv2d(in_planes=12, out_planes=1, kernel_size=1, ratio=0.25, stride=1, padding=0, dilation=1, groups=1, bias=True, K=4,temperature=37, init_weight=True)\n","  def forward(self, x):\n","    #x = self.conv1(x)\n","    x = self.dconv1(x)\n","    x = shift(x)\n","    #x = self.conv2(x)\n","    x = self.dconv2(x)\n","    return x\n","class SGU(nn.Module):\n","  def __init__(self, dim = 3):\n","    super(SGU, self).__init__()\n","    self.catConv =  nn.Conv2d(1, 1, kernel_size=1)\n","    self.norm1 = nn.LayerNorm([1, patch_size, patch_size])\n","    self.conv = nn.Conv2d(1,8,1,1)\n","    self.project_in = nn.Conv2d(1, 16, kernel_size=1)\n","    self.dwconv = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1, groups=16, bias=False)\n","    self.project_out = nn.Conv2d(8, 1, kernel_size=1)\n","  def forward(self, x):\n","    catOut = self.catConv(x)\n","    x = catOut\n","    x = self.norm1(x)\n","    x = self.project_in(x)\n","    x1, x2 = self.dwconv(x).chunk(2, dim=1)\n","    x = F.gelu(x1) * x2\n","    catOut = self.conv(catOut)\n","    x = x + catOut\n","    x = self.project_out(x)\n","    return x\n","\n","class CAMixer(nn.Module):\n","  def __init__(self):\n","    super(CAMixer, self).__init__()\n","    self.vit = vit\n","    self.csc = CSC()\n","    feature_dimension = 4\n","    self.BiAttention = BiAttention(feature_dim=feature_dimension)\n","    self.sgu = SGU()\n","    self.conv1x1 = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1)\n","    self.linear1=nn.Linear(patch_size * patch_size * 1, 20)\n","    self.linear2=nn.Linear(20, 2)\n","    self.conv1x1 = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1)\n","  def forward(self, img):\n","    first_channel = img[:, 0, :, :]\n","    first_channel = first_channel.unsqueeze(1)\n","    second_channel = img[:, 1, :, :]\n","    second_channel = second_channel.unsqueeze(1)\n","    in_x = img.reshape(img.shape[0],-1)\n","\n","    vitOut11 = self.vit(first_channel)\n","    cscOut11 = self.csc(first_channel)\n","    catOut11 = torch.cat((vitOut11, cscOut11), 1)\n","    catOut11 = self.conv1x1(catOut11)\n","    sguOut11 = self.sgu(first_channel)\n","    vitOut21 = self.vit(second_channel)\n","    cscOut21 = self.csc(second_channel)\n","    catOut21 = torch.cat((vitOut21, cscOut21), 1)\n","    catOut21 = self.conv1x1(catOut21)\n","    sguOut21 = self.sgu(second_channel)\n","    BiAttentionout11 = self.BiAttention(catOut11,sguOut11)\n","    BiAttentionout21 = self.BiAttention(catOut21,sguOut21)\n","    x = self.BiAttention(BiAttentionout11,BiAttentionout21)\n","    out = x.view(x.size(0), -1)\n","    out1 = self.linear1(out)\n","    out1 = self.linear2(out1)\n","    return in_x,out1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HWb7FVGLg_94"},"outputs":[],"source":["from ptflops import get_model_complexity_info\n","criterion = nn.CrossEntropyLoss()\n","model = CAMixer().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=lr) #\n","scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGbXTFUV1xx4"},"outputs":[],"source":["import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","from tqdm import tqdm\n","import time\n","\n","# 网络训练循环\n","outputs = np.zeros((ylen, xlen))\n","for epoch in range(20):\n","    epoch_loss = 0\n","    epoch_accuracy = 0\n","    all_in_x = []\n","    for data, label in tqdm(train_loader):\n","        data = data.to(device)\n","        label = label.to(device)\n","\n","        in_x, output = model(data)\n","        loss = criterion(output, label)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        acc = (output.argmax(dim=1) == label).float().mean()\n","        epoch_accuracy += acc / len(train_loader)\n","        epoch_loss += loss / len(train_loader)\n","\n","        # 存储 in_x\n","        all_in_x.append(in_x.detach().cpu().numpy())\n","    print(f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3NNwWrxBhG_I"},"outputs":[],"source":["istrain=False\n","model.eval()\n","with torch.no_grad():\n","  outputs = np.zeros((ylen, xlen))\n","  for i in range(ylen):\n","    for j in range(xlen):\n","      if preclassify_lab[i, j] != 1.5 :\n","        outputs[i, j] = preclassify_lab[i, j]\n","      else:\n","        img_patch = x_test[i*xlen+j, :, :, :]\n","        img_patch = img_patch.reshape(1, img_patch.shape[0], img_patch.shape[1], img_patch.shape[2])\n","        img_patch = torch.FloatTensor(img_patch).to(device)\n","        in_x, prediction = model(img_patch)\n","        prediction = np.argmax(prediction.detach().cpu().numpy(), axis=1)\n","        outputs[i, j] = prediction+1\n","\n","  outputs = outputs-1\n","\n","\n","plt.imshow(outputs, 'gray')\n","\n","\n","res = outputs*255\n","res = postprocess(res)\n","evaluate(im_gt, res)\n","plt.imshow(res, 'gray')\n","plt.imsave('result.png', res, cmap='gray')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":0}